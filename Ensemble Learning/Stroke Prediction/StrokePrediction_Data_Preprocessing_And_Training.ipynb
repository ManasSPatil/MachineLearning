{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StrokePrediction-Data Preprocessing And Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK0tC6b4xqJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299de544-ac39-4034-a288-068ff94060e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5iGpIJDlrU1"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/kaggle/StrokePrediction\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u52GQxTVlssU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b7d1f9-d3f6-491b-ad9a-52d9c62716de"
      },
      "source": [
        "%cd /content/gdrive/My Drive/kaggle/StrokePrediction"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/kaggle/StrokePrediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppWbjJSwp7ze",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2f3b70-3a07-4b46-a545-529e834c015a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature_names.pickle\t\t    model.pickle\t  X_test.pickle\n",
            "healthcare-dataset-stroke-data.csv  model_stacked.pickle  y_re.pickle\n",
            "kaggle.json\t\t\t    X_re.pickle\t\t  y_test.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0fEq8FJFG12"
      },
      "source": [
        "#Loading the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaShGtr7GUKp"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMf3tpa0FzI6"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzBWMhjCGXMA"
      },
      "source": [
        "Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "jmlU-VVDF578",
        "outputId": "ea649c84-3c57-4c35-d48e-d9ae1dcae6f3"
      },
      "source": [
        "dataset=pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\r\n",
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>ever_married</th>\n",
              "      <th>work_type</th>\n",
              "      <th>Residence_type</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>smoking_status</th>\n",
              "      <th>stroke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9046</td>\n",
              "      <td>Male</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51676</td>\n",
              "      <td>Female</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>202.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31112</td>\n",
              "      <td>Male</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.5</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60182</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.4</td>\n",
              "      <td>smokes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1665</td>\n",
              "      <td>Female</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>18234</td>\n",
              "      <td>Female</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Urban</td>\n",
              "      <td>83.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>44873</td>\n",
              "      <td>Female</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Urban</td>\n",
              "      <td>125.20</td>\n",
              "      <td>40.0</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>19723</td>\n",
              "      <td>Female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Self-employed</td>\n",
              "      <td>Rural</td>\n",
              "      <td>82.99</td>\n",
              "      <td>30.6</td>\n",
              "      <td>never smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>37544</td>\n",
              "      <td>Male</td>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Private</td>\n",
              "      <td>Rural</td>\n",
              "      <td>166.29</td>\n",
              "      <td>25.6</td>\n",
              "      <td>formerly smoked</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>44679</td>\n",
              "      <td>Female</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Govt_job</td>\n",
              "      <td>Urban</td>\n",
              "      <td>85.28</td>\n",
              "      <td>26.2</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5110 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  gender   age  ...   bmi   smoking_status stroke\n",
              "0      9046    Male  67.0  ...  36.6  formerly smoked      1\n",
              "1     51676  Female  61.0  ...   NaN     never smoked      1\n",
              "2     31112    Male  80.0  ...  32.5     never smoked      1\n",
              "3     60182  Female  49.0  ...  34.4           smokes      1\n",
              "4      1665  Female  79.0  ...  24.0     never smoked      1\n",
              "...     ...     ...   ...  ...   ...              ...    ...\n",
              "5105  18234  Female  80.0  ...   NaN     never smoked      0\n",
              "5106  44873  Female  81.0  ...  40.0     never smoked      0\n",
              "5107  19723  Female  35.0  ...  30.6     never smoked      0\n",
              "5108  37544    Male  51.0  ...  25.6  formerly smoked      0\n",
              "5109  44679  Female  44.0  ...  26.2          Unknown      0\n",
              "\n",
              "[5110 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oy572HuVxfs"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViUSzXmoV-JE"
      },
      "source": [
        "Let's see which columns have null values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD03zfk7V27U",
        "outputId": "743eeb6a-82a8-4229-8839-7b346c32a7db"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5110 entries, 0 to 5109\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   id                 5110 non-null   int64  \n",
            " 1   gender             5110 non-null   object \n",
            " 2   age                5110 non-null   float64\n",
            " 3   hypertension       5110 non-null   int64  \n",
            " 4   heart_disease      5110 non-null   int64  \n",
            " 5   ever_married       5110 non-null   object \n",
            " 6   work_type          5110 non-null   object \n",
            " 7   Residence_type     5110 non-null   object \n",
            " 8   avg_glucose_level  5110 non-null   float64\n",
            " 9   bmi                4909 non-null   float64\n",
            " 10  smoking_status     5110 non-null   object \n",
            " 11  stroke             5110 non-null   int64  \n",
            "dtypes: float64(3), int64(4), object(5)\n",
            "memory usage: 479.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg2FED6YXXfs"
      },
      "source": [
        "But first,let's seperate the dataset into dependent variables and independent variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QAq--UvXmnK"
      },
      "source": [
        "Y=dataset[\"stroke\"]#dependent variables\r\n",
        "X=dataset.drop(columns=[\"id\",\"stroke\"]) #independent variables"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kH3MBymWI4i"
      },
      "source": [
        "From above we see that only the bmi column has null values. So , we need to **impute the missing values** in the bmi column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ojp8beFuDNL"
      },
      "source": [
        "###Imputing missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLmmE1EZaceL"
      },
      "source": [
        "We are going to fill the missing values with the mean of BMI column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM34NaP3WXxW"
      },
      "source": [
        "X['bmi'].fillna(X['bmi'].mean(), inplace = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLw9iKgJbhTL"
      },
      "source": [
        "###Applying dummy encoding  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esN7C-JtmTv9"
      },
      "source": [
        "Dummy coding scheme is similar to one-hot encoding. It transforms the categorical variable into a set of binary variables (also known as **dummy variables**). In one-hot encoding, for N categories in a variable, it uses N binary variables. The dummy encoding is a small improvement over one-hot-encoding. Dummy encoding uses N-1 features to represent N labels/categories.\r\n",
        "\r\n",
        "[Source](https://www.analyticsvidhya.com/blog/2020/08/types-of-categorical-data-encoding/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3et-6annbgs6"
      },
      "source": [
        "X=pd.get_dummies(X,drop_first=True) #experiment with drop_first\r\n",
        "#X=X.drop(columns=[\"gender_Other\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "hWT01aADqBjN",
        "outputId": "beb5e2c2-5d29-4879-9088-1a8f40773c12"
      },
      "source": [
        "X"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>hypertension</th>\n",
              "      <th>heart_disease</th>\n",
              "      <th>avg_glucose_level</th>\n",
              "      <th>bmi</th>\n",
              "      <th>gender_Male</th>\n",
              "      <th>gender_Other</th>\n",
              "      <th>ever_married_Yes</th>\n",
              "      <th>work_type_Never_worked</th>\n",
              "      <th>work_type_Private</th>\n",
              "      <th>work_type_Self-employed</th>\n",
              "      <th>work_type_children</th>\n",
              "      <th>Residence_type_Urban</th>\n",
              "      <th>smoking_status_formerly smoked</th>\n",
              "      <th>smoking_status_never smoked</th>\n",
              "      <th>smoking_status_smokes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>228.69</td>\n",
              "      <td>36.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202.21</td>\n",
              "      <td>28.893237</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>105.92</td>\n",
              "      <td>32.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>171.23</td>\n",
              "      <td>34.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>79.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>174.12</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>83.75</td>\n",
              "      <td>28.893237</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>125.20</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>82.99</td>\n",
              "      <td>30.600000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>51.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>166.29</td>\n",
              "      <td>25.600000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5109</th>\n",
              "      <td>44.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85.28</td>\n",
              "      <td>26.200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5110 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  hypertension  ...  smoking_status_never smoked  smoking_status_smokes\n",
              "0     67.0             0  ...                            0                      0\n",
              "1     61.0             0  ...                            1                      0\n",
              "2     80.0             0  ...                            1                      0\n",
              "3     49.0             0  ...                            0                      1\n",
              "4     79.0             1  ...                            1                      0\n",
              "...    ...           ...  ...                          ...                    ...\n",
              "5105  80.0             1  ...                            1                      0\n",
              "5106  81.0             0  ...                            1                      0\n",
              "5107  35.0             0  ...                            1                      0\n",
              "5108  51.0             0  ...                            0                      0\n",
              "5109  44.0             0  ...                            0                      0\n",
              "\n",
              "[5110 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JliomdEPUlIw"
      },
      "source": [
        "Save the feature names for later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QECw61XmUkQx"
      },
      "source": [
        "import pickle as pk\r\n",
        "with open(\"feature_names.pickle\",\"wb\") as f:\r\n",
        "  pk.dump(X.columns.tolist(),f)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgEgP83TqywH"
      },
      "source": [
        "###Splitting into training set and testing set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I8NovdCnkU1"
      },
      "source": [
        "After applying dummy encoding we must split the dataset into training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ENJtNTWqy87"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXOgWJqCuMeJ"
      },
      "source": [
        "###Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK218qZVqnx3"
      },
      "source": [
        "Now we need to scale the numbers in the numerical columns ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9pikBuUsVUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177bede0-6859-459a-e3dc-de1f76304f73"
      },
      "source": [
        "from sklearn.preprocessing import  MinMaxScaler\r\n",
        "min_max=MinMaxScaler()\r\n",
        "X_train[[\"age\",\"avg_glucose_level\",\"bmi\"]]=min_max.fit_transform(X_train[[\"age\",\"avg_glucose_level\",\"bmi\"]])\r\n",
        "X_test[[\"age\",\"avg_glucose_level\",\"bmi\"]]=min_max.transform(X_test[[\"age\",\"avg_glucose_level\",\"bmi\"]])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value[:, i].tolist())\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTH6v8Mmuaih"
      },
      "source": [
        "###Oversampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKY_nhfeg-Qj"
      },
      "source": [
        "Oversampling is done to compensate for the lack of  data points of a particular class. In this case , the positive class (1) has very less samples as compared to the negative class (0).We will be using  SVMSMOTE for adjusting the class distribution of the data.</br>\r\n",
        "**SVMSMOTE** is a variant of the SMOTE algorithm . It uses the SVM algorithm to detect samples to use for generating new synthetic samples .</br>\r\n",
        "[Source](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SVMSMOTE.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B10f2VRgudb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac51dff-23a9-4214-c80c-cc80a6e3ea17"
      },
      "source": [
        "from imblearn.over_sampling import SVMSMOTE\r\n",
        "sm=SVMSMOTE(random_state=42)\r\n",
        "X_re,y_re=sm.fit_resample(X_train,y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq0kYKospecR"
      },
      "source": [
        "#Model building and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnvwvh2dlHCv"
      },
      "source": [
        "Ensemble learning is the process by which multiple learning algorithms are combined in order to obtain better predictive performance as compared to the constituent learning algorithms.Here, we will be experimenting with two ensembling methods : **blending and stacking**. </br>\r\n",
        "[Reference for blending](https://machinelearningmastery.com/blending-ensemble-machine-learning-with-python/) <br>\r\n",
        "[Reference for stacking](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFbwXK3ZoDwx"
      },
      "source": [
        "###Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FDaucNppqfg"
      },
      "source": [
        "Importing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUB5-ZF9pdnq"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score\r\n",
        "from numpy import hstack"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRtnf7vGrHrq"
      },
      "source": [
        "Initializing base models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R85jgZjXrHIU"
      },
      "source": [
        "def get_models():\r\n",
        "  models=list()\r\n",
        "  models.append((\"lr\",LogisticRegression()))\r\n",
        "  models.append((\"rf\",RandomForestClassifier()))\r\n",
        "  models.append((\"nb\",GaussianNB()))\r\n",
        "  models.append((\"svm\",SVC()))\r\n",
        "  return models"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6giqVR74sD0j"
      },
      "source": [
        "Training function for the blended model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SvA6Ui-eOaE"
      },
      "source": [
        "def fit_ensemble(models,X_train,X_val,y_train,y_val):#this function returns the fitted blended model \r\n",
        "  print(50*\"-\",\"Phase 1:Fit blender model\",50*\"-\")\r\n",
        "  meta_X=list() #list for containing the predictions made by the base models on the validation data\r\n",
        "  for name,model in models:\r\n",
        "    print(\"Fitting to base model: {} \".format(name))\r\n",
        "    model.fit(X_train,y_train) #fit base model on the training data\r\n",
        "    y=model.predict(X_val) #making predictions on validation data ,these predictions will be used as the features for the blender model\r\n",
        "    y=y.reshape(len(y),1)\r\n",
        "    meta_X.append(y)\r\n",
        "\r\n",
        "  meta_X=hstack(meta_X)\r\n",
        "  blender=RandomForestClassifier() #intialise blender model\r\n",
        "  print(\"Fitting blender model now!\")\r\n",
        "  blender.fit(meta_X,y_val)\r\n",
        "  return blender"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvM-qY5oj5zi"
      },
      "source": [
        "Prediction function  for the blended model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdQsYImWj9bE"
      },
      "source": [
        "def predict_blend(models,blender,X_test): #this function returns the final predictions done by the blender model\r\n",
        "  print(50*\"-\",\"Phase 2:Creating final predictions\",50*\"-\")\r\n",
        "  meta_X=list()\r\n",
        "  for name, model in models:\r\n",
        "    print(\"Making test set predictions for base model: {}\".format(name))\r\n",
        "    y=model.predict(X_test)\r\n",
        "    y=y.reshape(len(y),1)\r\n",
        "    meta_X.append(y)\r\n",
        "  meta_X=hstack(meta_X)\r\n",
        "  print(\"Creating final blender predictions now!\")\r\n",
        "  return blender.predict_proba(meta_X)[:,1],blender.predict(meta_X)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc3D-vfolsV-"
      },
      "source": [
        "When we tie it up all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3PkqEgSlogv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3022d0-dd0e-4e7c-ea36-1ff5995132b6"
      },
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(X_re,y_re,test_size=0.4,random_state=1) #splitting full train set into : training set ,validation set\r\n",
        "models=get_models() #intialize base models\r\n",
        "blender=fit_ensemble(models,X_train,X_val,y_train,y_val) #fit blender model\r\n",
        "yhat,y_pred=predict_blend(models,blender,X_test) #predict the final probabilities\r\n",
        "auc=roc_auc_score(y_test,yhat)\r\n",
        "print(\"AUC score after blending:\",auc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------- Phase 1:Fit blender model --------------------------------------------------\n",
            "Fitting to base model: lr \n",
            "Fitting to base model: rf \n",
            "Fitting to base model: nb \n",
            "Fitting to base model: svm \n",
            "Fitting blender model now!\n",
            "-------------------------------------------------- Phase 2:Creating final predictions --------------------------------------------------\n",
            "Making test set predictions for base model: lr\n",
            "Making test set predictions for base model: rf\n",
            "Making test set predictions for base model: nb\n",
            "Making test set predictions for base model: svm\n",
            "Creating final blender predictions now!\n",
            "AUC score after blending: 0.8055023521505376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fedTXG5cw4Eh"
      },
      "source": [
        "Save the blended model for later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9xLrmmXw3sA"
      },
      "source": [
        "import pickle as pk\r\n",
        "with open(\"model.pickle\",\"wb\") as f:\r\n",
        "  pk.dump(blender,f)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsElQc4EoKCd"
      },
      "source": [
        "###Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_uERbQwNoPT"
      },
      "source": [
        "Importing essentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtHE96eizZ-E"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score,RepeatedStratifiedKFold\r\n",
        "from sklearn.ensemble import StackingClassifier"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o_5XLrMN0RI"
      },
      "source": [
        "Function to create the stacked model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxw1txMh3S0w"
      },
      "source": [
        "def get_stacked_model(models):\r\n",
        "  meta_model=RandomForestClassifier() # meta model that will make the final predictions\r\n",
        "  model=StackingClassifier(estimators=models,final_estimator=meta_model,cv=5)\r\n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXNjnBUgOBSj"
      },
      "source": [
        "Combining everything and making predictions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua77VoTi4bim",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7365bc11-a79d-4904-e484-1681410ee21d"
      },
      "source": [
        "models=get_models() # get the base models\r\n",
        "stacked=get_stacked_model(models) # create the stacked model\r\n",
        "stacked.fit(X_re,y_re) #fit to the stacked model\r\n",
        "y_pred=stacked.predict_proba(X_test)[:,1]  \r\n",
        "auc=roc_auc_score(y_test,y_pred)\r\n",
        "print(\"Final auc score after stacking:\",auc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final auc score after stacking: 0.7474714381720429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYpyQ7VZSo7Z"
      },
      "source": [
        "Saving data for hyperparameter optimisation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPCmM_lSqNA"
      },
      "source": [
        "#saving the resampled training data\r\n",
        "with open(\"X_re.pickle\",\"wb\") as f:\r\n",
        "  pk.dump(X_re,f)\r\n",
        "with open(\"y_re.pickle\",\"wb\") as f:\r\n",
        "  pk.dump(y_re,f)  \r\n",
        "  \r\n",
        "#saving the test data\r\n",
        "with open(\"X_test.pickle\",\"wb\") as f:\r\n",
        "  pk.dump(X_test,f)\r\n",
        "with open(\"y_test.pickle\",\"wb\") as f:\r\n",
        "  pk.dump(y_test,f)"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}